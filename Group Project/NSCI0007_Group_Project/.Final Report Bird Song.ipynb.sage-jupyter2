{"backend_state":"running","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-2c3d00ce-98fc-49d5-b69a-00a8be20893a.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1616097401340,"exec_count":1,"id":"5eff98","input":"import warnings\nwarnings.filterwarnings(\"ignore\") # To remove warnings","kernel":"python3","pos":6,"start":1616097401333,"state":"done","type":"cell"}
{"cell_type":"code","end":1616097406417,"exec_count":2,"id":"094d8d","input":"import notes_identifier\nimport fourier_trans\ndominant_frequency = fourier_trans.dominant_freq_extractor('Test Files//E_high_note.wav',1)\nnotes_identifier.get_note_info(dominant_frequency, corr = 3, get_nearest = True)","kernel":"python3","output":{"0":{"data":{"text/plain":"('660.1796407185628Hz', 'E', 5)"},"exec_count":2}},"pos":10,"start":1616097401345,"state":"done","type":"cell"}
{"cell_type":"code","end":1616097409155,"exec_count":3,"id":"5b4c75","input":"import fourier_trans\nfourier_trans.dominant_freq_extractor_string('Database Files//Wren.wav', 1)","kernel":"python3","output":{"0":{"name":"stdout","text":"Dominant Frequency 1 : 7035.4165170878805\n"}},"pos":13,"start":1616097406425,"state":"done","type":"cell"}
{"cell_type":"code","end":1616097412088,"exec_count":4,"id":"5ff873","input":"import fourier_trans\nfourier_trans.dominant_freq_extractor_string('Test Files//Wren 2.wav', 1)","kernel":"python3","output":{"0":{"name":"stdout","text":"Dominant Frequency 1 : 4583.846393034825\n"}},"pos":15,"start":1616097409172,"state":"done","type":"cell"}
{"cell_type":"code","end":1616097413277,"exec_count":5,"id":"29b274","input":"import fourier_trans\nfourier_trans.dominant_freq_extractor_string('Test Files//wren3.wav', 1)","kernel":"python3","output":{"0":{"name":"stdout","text":"Dominant Frequency 1 : 5385.4664210704605\n"}},"pos":16,"start":1616097412121,"state":"done","type":"cell"}
{"cell_type":"code","end":1616097414720,"exec_count":6,"id":"33c066","input":"import librosa\nimport librosa.display\nimport numpy as np\nfrom scipy.fft import fft, fftfreq\nfrom pydub import AudioSegment\n\n\n\ndef freq_change(audiofile):\n\n    dom_f = []\n    time = []\n    #sr represents the sample rate\n    audio, sr = librosa.load(audiofile)\n\n    #get number of samples for 0.1 seconds\n    buffer = 0.1 * sr\n\n    samples_total = len(audio)\n    samples_wrote = 0\n    counter = 1\n\n    while samples_wrote < samples_total:\n        #check if the buffer is not exceeding total samples\n        if buffer > (samples_total - samples_wrote):\n            buffer = samples_total - samples_wrote\n\n        #create a 0.1 second block of the audio data\n        block = audio[int(samples_wrote) : int((samples_wrote + buffer))]\n\n        #perform a FFT to find the dominant frequency per 0.1 second\n        N = len(block)\n        #power in db is the modulus of the fourier transform ^2 as certain elements in the array are complex\n        yf = np.abs(fft(block))**2\n        #create a frequency vector\n        xf = fftfreq(N, 1 / sr)\n        #find the dominant frequency\n        maxpower = np.argmax(yf)\n        strongfreq = xf[maxpower]\n\n        dom_f.append(strongfreq)\n        time.append(0.1*counter)\n\n        counter += 1\n        samples_wrote += buffer\n\n    x = []\n    #filtering out frequencies below 20 Hz as this is below the human range of hearing\n    if min(dom_f) < 20:\n        while min(dom_f) < 20:\n            dom_f.remove(min(dom_f))\n    x.append(min(dom_f))\n    x.append(max(dom_f))\n    x.append(sum(dom_f)/len(dom_f))\n    #x is a list containing the minimum, maximum and average frequency\n    return x\n\n#testing the code on a wood pigeon bird song\nfreq_change('Database Files//Wood pigeon.wav')","kernel":"python3","output":{"0":{"data":{"text/plain":"[140.0, 930.0, 414.3907445418921]"},"exec_count":6}},"pos":18,"start":1616097413291,"state":"done","type":"cell"}
{"cell_type":"code","end":1616097415296,"exec_count":7,"id":"fed6d2","input":"import which_species\nwhich_species.closest_species('Test Files//Wood Pigeon 2.wav')","kernel":"python3","output":{"0":{"name":"stdout","text":"The song is the song of a Wood pigeon\n"}},"pos":23,"start":1616097414739,"state":"done","type":"cell"}
{"cell_type":"code","end":1616097418531,"exec_count":8,"id":"be38de","input":"import which_species\nwhich_species.closest_species('Test Files//Wren 2.wav')","kernel":"python3","output":{"0":{"name":"stdout","text":"The song is the song of a Great tit\n"}},"pos":25,"start":1616097415335,"state":"done","type":"cell"}
{"cell_type":"code","end":1616097433930,"exec_count":9,"id":"b9c094","input":"import PCA_Analysis as PA\nPA.analyse_PCA_birds(num = 10, rmv = True, length = 30, parts = 6, mode = 'PCA')","kernel":"python3","metadata":{"cocalc":{"outputs":{"0":{"name":"input","opts":{"password":false,"prompt":"Are you sure you want to delete /home/user/Project/splits? Y/N"},"output_type":"stream","value":"Y"},"1":{"name":"input","opts":{"password":false,"prompt":"Are you sure you want to delete /home/user/Project/cleaned? Y/N"},"output_type":"stream","value":"Y"}}}},"output":{"0":{"name":"input","opts":{"password":false,"prompt":"Are you sure you want to delete /home/user/Assessments/NSCI0007_Group_Project/splits? Y/N"},"value":"Y"},"1":{"name":"input","opts":{"password":false,"prompt":"Are you sure you want to delete /home/user/Assessments/NSCI0007_Group_Project/cleaned? Y/N"},"value":"Y"},"2":{"data":{"image/png":"f190cd771309f4e161ea827a694d79756e2eab86","text/plain":"<Figure size 648x648 with 1 Axes>"},"metadata":{"image/png":{"height":569,"width":562},"needs_background":"light"}}},"pos":29,"scrolled":false,"start":1616097418545,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"13f1d7","input":"**We have encountered multiple warnings whilst using the Librosa library, but they did not affect our output. The code below removes the different warnings produced:**","pos":5,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"14dbae","input":"In order to analyse the audio signal, we employed the use of the Fourier transform to find the most powerful or 'dominant' frequencies in the signal. If the dominant frequency of a bird song differs between species of birds, the information gained by applying the Fourier transform may help identify a species from its song.\n\nSounds can be created from the superposition of many sine waves with different frequencies. For example, below a sound wave made from 4 different superimposed sine waves is plotted in the time domain.\n\n<!-- ![](Images//super_time_domain.png) -->\n<img src=\"Images//super_time_domain.png\" alt=\"supertimedom\" style=\"width: 800px;\"/>\n\nThe Fourier transform will convert this signal to the frequency domain. This allows us to find the specific frequencies of the individual sine waves that were superimposed to form the sound wave.\n\n<!-- ![](Images//superposition_freq_domain.png) -->\n<img src=\"Images//superposition_freq_domain.png\" alt=\"wrenfreqdom\" style=\"width: 800px;\"/>\n\nFrom this plot we can see that our sound was created by sine waves with frequencies around: 400Hz, 2000Hz, 2500Hz and 4000Hz. The peak with the greatest height (greatest power) will tell us the position of the dominant frequency for the sound. In this particular case the frequencies at 400Hz, 2000Hz and 2500Hz are all equally dominant.\n\n","pos":7,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"3838f9","input":"As we can see the function correctly determined that the audio recording is likely to be the song of a wood pigeon.\n\nHowever, other species of birds can have very similar songs containing similar frequencies. Let's test the code on an audio recording of a wren's song, different to that used in the creation of the database.","pos":24,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"3a98bf","input":"We tried the same function on two other wren song files, which gave quite different dominant frequencies:","pos":14,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"3fd274","input":"### Future extensions: Using PCA\nAs described in previous sections, finding the different characteristics of bird songs is an extremely complicated task. Many factors need to be considered and compared while doing bird song analysis, therefore it is useful if we can find methods to take account into all characteristics for a more accurate prediction. Hence, a preliminary attempt of identifying bird songs has been made using Principal Component Analysis (PCA) [5]. It shows the different correlations of various characteristic data being fed in, by converting them to points on a 2D graph. The more correlated the data is, the more clustered the points are on such graphs. Note that the algorithms behind PCA will not be discussed as they are not the main focus of this report. We hope that this section will provide more insight and ideas for future work.\n\n#### Method\n\nThe method used in this section is very different to the methods used in previous sections. Firstly, we \"cleanse\" the birdsong audio file by making them the same duration (30 seconds). Audio files shorter than this duration will be incremented with silence to fit such duration (padding); for audio files longer than this duration, we will take only the first 30 seconds of it (cutting). Then we split them into equal parts and run a fourier transform of each of the split audio files as before. The real parts of the output are being put into a database, as well as their respective audio sources. Next, we create a function `get_PCA(mode)` to run a PCA analysis on the database. Functions for such analysis are provided in the Scikit-Learn Python library [6]. Lastly, we plot the results.\n\nBelow is an example of a PCA plot of 3 different flowers taken from an example from the scikit-learn documentation [7]. We can clearly see that the data for the same type of flower is clustered together, as indicated by the colors.\n\n<img src=\"Images//sphx_glr_plot_incremental_pca_001.png\" alt=\"egPCA\" style=\"width: 600px\" />\n<!-- <img src=\"Images//tsne_example.png\" alt=\"egTSNE\" style=\"width: 340px;\"> -->\n\nWith reference to this, we would also expect data points for the split birdsong audios clustering similarly.\n\nBelow is an attempt of using PCA on our audio files. Here we created a function `analyse_PCA_birds` to analyse and plot the data. \n(We have included also a function to delete folders \"splits\" and \"cleaned\" generated. To prevent deleting important folders in case of an error: **Please input Y into the following input boxes**)\n\n","pos":28,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"415fb1","input":"## Introduction\n\n**We are using Librosa, a package not included within CoCalc, for audio signal processing. To install Librosa on Python, the following command must be run in the CoCalc terminal:** ```pip install librosa```\n\n\n\nBirdwatching, or ‘twitching’, is a common hobby which involves observing and identifying different species of birds. One way to identify a species of bird is to listen to its vocalisations. These are sounds produced by birds as a form of communication. These may be to attract a mate, establish territory or even to signal alarm. Bird vocalisations are produced by the ‘sound-producing organ; called the syrinx’[1]. Each species of bird can produce a unique call due to the complicated superposition of sound waves of different frequency and amplitude created by their syrinx. The melodious songs produced served as inspiration for our project, in which we tasked ourselves with the identification of birds from a recording of their respective song using Python.\n\nFrom the outset, we acknowledged that this is a challenging goal for our level of experience, and so we set out to use Python to create an algorithm capable of completing a Fast Fourier Transform on simple audio files. We found that the output from these transforms was particularly useful for analysing properties associated with sound frequency. In recognition of the complexity of our task, we decided that it would be more appropriate to determine whether manipulations of frequency data from recordings of bird songs had the potential to be used to identify birds. After refocusing our aim, we considered ways that we could reach a conclusion and set ourselves a goal of producing a database containing different species of bird and frequency properties of their respective bird song. In attempt to get an idea of how this database could function, we began working on a simpler database constructed of piano notes and their dominant frequencies. Using the knowledge gained from this, we then began working towards our overall goal of creating the bird database.","pos":2,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"439604","input":"## Conclusion\n\nThroughout this project, we steadily became familiar with the Librosa Python library and its functionality. In particular, we utilised the Fourier Transform to gain insight into the nature of bird songs and sound in general. We quickly recognised the difficulty of the overall task and decided to work towards producing a database of frequency properties for different bird species. Through this process, we learned that analysing the frequencies of bird songs has limited usefulness in identifying a species, as many birds sing in similar frequency ranges, and may have a variety of calls which makes identification more complicated. For bird species with a very distinctive frequency range (e.g. the wood pigeon, which sings at a low frequency), our code was more successful in identifying the species, but in most other cases it was unsuccessful.\n\nIn conclusion, we managed to produce a database and develop code that is able to compare audio files to reference files within the database. Unfortunately, the frequency data that we were able to extract from the bird songs we worked with was simply not extensive enough to consistently identify birds. Our database can however be extended and refined in the future to overcome the complications identified throughout. Furthermore, future investigations for identifying bird species by vocalisation can be done using other analysis techniques, such as the proposed PCA method.\n","pos":31,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"48a49c","input":"## Limitations and Extensions\n\nAlthough we managed to make some progress with our goal of identifying birds from their song, our current programme has many limitations.\nBird songs are very sophisticated and are therefore difficult to identify with the characteristics that we were able to extract. Ideally our database would allow for comparison between patterns of frequencies produced and the length of single 'verse' of a bird's song. However, we were unable to extract this information from our audio files during this project due to the complexity of the code required.  \n\n\nA further limitation is that our code would only be able to identify birds that have had their characteristics inputted into the database. Currently our database is very small, and our programme is therefore not capable of identifying many birds. The database could be extended using a webscraping algorithm that can extract the bird song audiofiles from a website, which is a much more efficient way of gathering the copious amounts of data required for this task. This classification problem could also be solved with more advanced methods such as supervised learning, which builds a predictive model based on training data. For example, the algorithm could take as input the raw audiofile of the bird song and map it to a probability of it belonging to a certain bird species.\nFurthermore, each species of bird is able to make different sounds to communicate different things, such as signaling distress or finding a mate. Our current approach would misidentify a bird if it were making a sound that we had not encountered. This could also be addressed by extending the database to include the alarm call and song of each of the birds.\n\n\nAnother issue that we wished to tackle was background noises which make bird identification more difficult. Birds produce their vocalisations in loud, natural environments meaning that other sounds are often captured during their songs and also during pauses between songs. One possible way of filtering out sounds during pauses would be to add a decibel threshold value below which sounds are ignored by the software.   We considered ways of minimising the contribution of this noise such as removing frequencies below the range. \n\nFinally, solely using frequency to identify birds is disadvantageous as most birds emit sounds within the 1kHz - 8kHz [4] , which is a narrow range given that the human ear can perceive sounds between 20Hz-20kHz.\n\n","pos":27,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"4ab316","input":"Here we can see that the function incorrectly determined that the song was that of a great tit.\n\nThis is likely because a lot of bird species will have similar dominant, minimum, maximum and average frequencies of their songs, making it hard for the function to correctly identify the correct species. Furthermore, a species of bird will have different types of calls for different purposes, which will likely differ greatly in frequency. Therefore, to account for this more parameters may need to be used or the different types of call may need to be added into the database.","pos":26,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"4ed4f6","input":"# Bird Song Audio Signal Analysis","pos":0,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"69dbf5","input":"## Recognising Bird Songs:","pos":11,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"7e342f","input":"### Comparing dominant frequency, minimum and maximum, and average frequency","pos":21,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"9a339a","input":"## Fourier Analysis\n\n### Introduction to Fourier Analysis and the Fourier transform","pos":3,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"ad5d78","input":"We now want to apply what we had learnt from using the Fourier transform on piano notes and chords to bird songs. For our code, we used birdsong audio files downloaded from the online website Xeno Canto [2]. Bird song frequencies do not necessarily correspond to a note, so we cannot apply the exact method above in this situation. However, the Fourier transform can still supply us with a lot of useful information that could be used to differentiate one song from another.\n\nFor example, the `dominant_freq_extractor_string` function was applied to the song of a wren, which returned a dominant frequency of 7035Hz.","pos":12,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"b89dba","input":"Fourier Analysis is a topic in mathematics which explores how functions can be approximated or expanded in terms of the trigonometric functions $\\sin$ and $\\cos$. The Fourier transform \n\n$\\hat f : \\mathbb R \\to \\mathbb C $ of a continuous function or signal $f(t)$ is defined as: $$\\hat f(k) := \\int_{- \\infty}^{+\\infty} f(t) e^{-2 \\pi i t k} dk $$\n\nIt converts the signal from the *time domain* to the *frequency domain*, allowing us to see the different frequencies present in the signal and their respective power. Indeed, the Fourier transform is a very powerful tool in audio signal processing and has many applications in industry. We intend on using the Fourier transform to extract some key frequencies present in the bird song recordings that could help us identify the species. ","pos":4,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"cd78db","input":"## Recognising Piano Notes","pos":8,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"d03906","input":"## References\n\n[1] Boswall J., How birds sing, The British Library, https://www.bl.uk/the-language-of-birds/articles/how-birds-sing#authorBlock1\n\n[2] Xeno Canto, https://www.xeno-canto.org\n\n[3] Hendrik Schreiber, Split audio on timestamps Librosa, 2020, https://stackoverflow.com/questions/60105626/split-audio-on-timestamps-librosa\n\n[4] All About Birds, Bird Songs Have Frequencies Higher Than Humans Can Hear?, 2009, https://www.allaboutbirds.org/news/do-bird-songs-have-frequencies-higher-than-humans-can-hear/\n\n[5] Jolliffe Ian T. and Cadima Jorge, Principal component analysis: a review and recent developments, Phil. Trans. R. Soc. A.3742015020220150202, 2016,\nhttp://doi.org/10.1098/rsta.2015.0202Do\n\n[6] Pedregosa et al., sklearn.decomposition.PCA,Scikit-learn: Machine Learning in Python, JMLR 12, pp. 2825-2830, 2011, https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n\n[7] Pedregosa et al., Incremental PCA ,Scikit-learn: Machine Learning in Python, JMLR 12, pp. 2825-2830, 2011, https://scikit-learn.org/stable/auto_examples/decomposition/plot_incremental_pca.html#sphx-glr-auto-examples-decomposition-plot-incremental-pca-py\n","pos":32,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"d5db20","input":"### Table of contents:\n- Introduction\n\n- Fourier Analysis\n\n- Working with piano notes and building a database\n\n- Recognising bird songs\n\n- Limitations and extensions\n\n- Conclusions\n\n- References","pos":1,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"d8f14a","input":"To visualise the frequency changes, we also extended the function to write another function `freq_graph(audiofile)` which can plot the dominant frequency per 0.1s against time:\n\n<!-- ![](Images//pigeongraphfinal.png) -->\n<img src=\"Images//pigeongraphfinal.png\" alt=\"pigeon\" style=\"width: 800px;\"/>","pos":19,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"de72c6","input":"#### Results\nThe graphs below show the result of the analysis using the PCA. Note that the colors indicating different bird species may vary for each output.\n\n<img src=\"Images//analyse_PCA.png\" alt=\"PCA\" style=\"width: 610px;\"/>\n<!-- <img src=\"Images//TSNE-Analysis.png\" alt=\"TSNE\" style=\"width: 540px;\"/> -->\n\nAs seen from the above, the points representing the different species of birds are largely overlapped and exhibit no noticeable clustering differences. Using our current database of bird songs, it is not possible to identify different bird species using PCA. This further emphasises our limitations as discussed previously. In theory, better results can be obtained using PCA if we could collect large amounts of bird song data for the selected birds, with similar audio lengths, together with filtering of the background noises. We can also take into account the different parameters as discussed in previous sections, and maybe factors which are not yet considered.\n","pos":30,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e535ba","input":"Having created a database containing the dominant frequency, minimum and maximum frequencies and average frequency for the songs of the 10 different species, we needed a way to compare them. Given an audio recording of a bird song from an unknown species, we wanted to to create a function (`closest_species`) that returned the species with a song most similar to that in the audio recording.\n\nTo do this we first calculated the dominant, minimum, maximum and average frequency for the unknown bird song. For example,\n\n\n|Parameter|Frequency (Hz)|\n|---|---|\n|Dominant frequency|4584|\n|Maximum frequency|8310|\n|Minimum frequency|60|\n|Average frequency|2850|\n\nEach of these parameters is then compared to the same parameter in the database and the average difference between the recording parameters and the database parameters is calculated for each species. The minimum of the differences is found and the species this difference corresponds to is outputted as the predicted species for this bird song.\n\nHere we test the code on an audio recording of a wood pigeon song (\"Wood Pigeon 2\"), a different one to the one used to create the database.","pos":22,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e81446","input":"As piano notes consist of specific frequencies, we considered this a good place to start applying our code to real life sounds. We wanted to create a function to identify the notes being played based on the dominant frequency. The ideas we developed doing this were a stepping stone towards identifying bird species from bird song using a database.\n\nTo do this we first created a database of each note that can be played on the piano and its corresponding frequency.\n\n\n<!-- ![](Images//frequencies_notes.png) -->\n<img src=\"Images//frequencies_notes.png\" alt=\"notes\" style=\"width: 400px;\"/>\n\nIf we perform a Fourier transform on the audio signal of a note being played on the piano, the most dominant frequency should be equal to the frequency corresponding to that note. Therefore, in order to identify which note is being played, the dominant frequency is located on the table and the corresponding note is found.\n\nTo be able to do this for any audio signal we created a function `dominant_freq_extractor(audio_file,n)` which analayses the audio file and returns the n most dominant frequencies for that signal.\n\nBelow, we test this on an audio recording of someone playing the piano note E in the 5th octave. From the output we can see that the dominant frequency is aorund 660Hz and comparing this to the table we can see that this does indeed correspond to the note E in the 5th octave. The slight difference between the dominant frequency and the frequency in the table may be due to tuning of the piano or inaccuracies in the audio recording.","pos":9,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"ea101c","input":"### Creating a database of 10 common bird species\n\nAt this point, we had a way to extract the dominant, minimum, maximum and average frequency for a bird's song. After comparing the graphs of dominant frequency over time (an example is shown above) of different bird species, we saw that there were some clear differences in the frequency range and pattern of frequencies, while those of the same species had similarities in their graphs. Therefore, we thought that using these additional parameters could help to more accurately identify the bird species than dominant frequency alone. We started to create a database of bird species using these four parameters.\n\nTen common bird species were chosen and these are shown below:\n\n* Blue Tit\n* Common Chaffinch\n* House Sparrow\n* European Robin\n* Blackbird\n* Wren\n* Common Starling\n* Wood Pigeon\n* Song Thrush\n* Great Tit\n\n<!-- ![](Images//Reference Table.png) -->\n<img src=\"Images//Reference Table.png\" alt=\"table\" style=\"width: 700px;\"/>","pos":20,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"fce1f0","input":"### Investigating how the dominant frequency of birdsong changes over time\n\nAfter using the Fourier transform to analyse multiple recordings of birdsong from the same species, it became apparent that the dominant frequencies change considerably between songs of the same species. This may be due to a species having many different types of song for different purposes. Therefore, it was clear to us that the dominant frequency alone would not be enough to differentiate between species.\n\nWe decided to investigate how the frequency of a bird's song changes over time, as this could help identify the unique singing pattern of a species. This would also allow us to identify the minimum and maximum frequencies the bird sings at (its frequency range), which we thought may be more distinctive of a species than the dominant frequency alone.\n\nTo do this, we created a function, `freq_change(audiofile)`, that split audio files into 0.1s time chunks [3] and applied the Fourier transform to each of these chunks, returning the dominant frequency. The dominant frequencies per 0.1 second were appended to a list, `dom_f`. This made it relatively simple to identify the minimum, maximum and average frequency of the audio file. The function returns a list with the minimum, maximum and average frequencies as its output, as the code below shows:","pos":17,"state":"done","type":"cell"}
{"id":0,"time":1616096972560,"type":"user"}
{"last_load":1616094482937,"type":"file"}